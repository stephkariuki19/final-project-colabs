{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNF4HGfNV0YotNSHZAmz8OO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephkariuki19/final-project-colabs/blob/main/projectIterOne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8gSXZ07gLoV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "DISEASES:\n",
        "THE DISEASES:\n",
        "Pneumonia\n",
        "Consolidation\n",
        "Infiltration\n",
        "Pneumothorax\n",
        "Asthma\n",
        "Emphysema\n",
        "Fibrosis\n",
        "Covid- 19\n",
        " Effusion\n",
        "Atelectasis\n",
        "Pleural_thickening\n",
        "Cardiomegaly\n",
        "Nodule Mass\n",
        "TB\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using langchain to load data from trusted sources"
      ],
      "metadata": {
        "id": "8sOu7IAXUZxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain-pinecone langchain-openai langchain"
      ],
      "metadata": {
        "id": "4YFyib5ujQMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community"
      ],
      "metadata": {
        "id": "U0Q8X0VOsfMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import AsyncHtmlLoader\n",
        "\n",
        "urls = [\"https://www.mayoclinic.org/diseases-conditions/enlarged-heart/symptoms-causes/syc-20355436\"]\n",
        "loader = AsyncHtmlLoader(urls)\n",
        "docs = loader.load()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT4_Wzo0j-el",
        "outputId": "d31fd26f-6fb2-44dc-dc16-ce2f64d320b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  2.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install html2text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L84fuJaPkW3h",
        "outputId": "41907d3c-801b-49d0-acb4-6059e0e40e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2020.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to output results of webpage only\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "\n",
        "# Define the topics of interest\n",
        "topics = ['symptoms', 'when to see a doctor', 'causes', 'risk factors', 'complications', 'prevention', 'vaccination']\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(docs)\n",
        "\n",
        "# Dictionary to store content for each topic\n",
        "topic_content = {topic: [] for topic in topics}\n",
        "\n",
        "# Iterate over transformed documents\n",
        "for doc in docs_transformed:\n",
        "    # Iterate over each topic\n",
        "    for topic in topics:\n",
        "        # Find the index of the topic in the page content\n",
        "        index = doc.page_content.lower().find(topic)\n",
        "        if index != -1:\n",
        "            # Find the end index of the topic's section\n",
        "            next_topic_index = len(doc.page_content)\n",
        "            for next_topic in topics:\n",
        "                next_index = doc.page_content.lower().find(next_topic)\n",
        "                if next_index != -1 and next_index > index:\n",
        "                    next_topic_index = min(next_topic_index, next_index)\n",
        "            # Extract content for the topic\n",
        "            topic_content[topic].append(doc.page_content[index:next_topic_index])\n",
        "\n",
        "# Print content for each topic\n",
        "for topic, content_list in topic_content.items():\n",
        "    print(f\"Content for topic '{topic}':\")\n",
        "    for content in content_list:\n",
        "        print(content)\n",
        "        print(\"---------------------\")\n"
      ],
      "metadata": {
        "id": "Ay3MTsmQkKRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to output results of webpage and save to my Google drive\n",
        "from google.colab import drive\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# Define the topics of interest\n",
        "topics = ['symptoms', 'when to see a doctor', 'causes', 'risk factors', 'complications', 'prevention', 'vaccination']\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(docs)\n",
        "\n",
        "# Dictionary to store content for each topic\n",
        "topic_content = {topic: [] for topic in topics}\n",
        "\n",
        "# Iterate over transformed documents\n",
        "for doc in docs_transformed:\n",
        "    # Iterate over each topic\n",
        "    for topic in topics:\n",
        "        # Find the index of the topic in the page content\n",
        "        index = doc.page_content.lower().find(topic)\n",
        "        if index != -1:\n",
        "            # Find the end index of the topic's section\n",
        "            next_topic_index = len(doc.page_content)\n",
        "            for next_topic in topics:\n",
        "                next_index = doc.page_content.lower().find(next_topic)\n",
        "                if next_index != -1 and next_index > index:\n",
        "                    next_topic_index = min(next_topic_index, next_index)\n",
        "            # Extract content for the topic\n",
        "            topic_content[topic].append(doc.page_content[index:next_topic_index])\n",
        "\n",
        "# Write content for each topic to pneumonia.txt in Google Drive\n",
        "file_path = '/content/drive/My Drive/Cardiomegaly.txt'\n",
        "with open(file_path, 'w', encoding='utf-8') as file:\n",
        "    for topic, content_list in topic_content.items():\n",
        "        file.write(f\"Content for topic '{topic}':\\n\")\n",
        "        for content in content_list:\n",
        "            file.write(content + \"\\n\")\n",
        "            file.write(\"---------------------\\n\")\n",
        "\n",
        "print(f\"Content written to {file_path} successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-XA88bfrorq",
        "outputId": "393df684-54a5-4f7c-c94c-e745fd815ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Content written to /content/drive/My Drive/Cardiomegaly.txt successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading data to a vector store"
      ],
      "metadata": {
        "id": "gEEWfyKtwTn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "iEciMcvRl-2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install qdrant-client"
      ],
      "metadata": {
        "id": "kfRKRdJnwVEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "    'https://d587747f-8acf-40ea-a289-8d8050de9a3f.us-east4-0.gcp.cloud.qdrant.io:6333',\n",
        "    api_key=\"orEjosb4oaqYDh5AGOqAd1Ab4Iyj1UR7vVgheTDIIL-JhE6kREt0LQ\",\n",
        ")"
      ],
      "metadata": {
        "id": "5Y1zgu0OwfEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client.recreate_collection(\n",
        "    collection_name='diseases',\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8dGTPQiwfHw",
        "outputId": "b22b445c-570f-449b-ef47-fa905ed3215c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the zip file containing the folder\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "8RQj5DHn6X4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Specify the folder path containing text files\n",
        "folder_path = r'/content/dataFolder'\n",
        "\n",
        "# Initialize lists to store startup data and vectors\n",
        "startup_data = []\n",
        "vectors = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.txt'):\n",
        "        # Load text data from the current file\n",
        "        with open(os.path.join(folder_path, file_name), 'r') as file:\n",
        "            content = file.read()\n",
        "            # Check if the text file contains JSON data\n",
        "            try:\n",
        "                data = json.loads(content)\n",
        "                startup_data.append(data)\n",
        "            except json.JSONDecodeError:\n",
        "                # If not JSON, assume it contains vectors (e.g., numpy arrays)\n",
        "                vector = np.fromstring(content, dtype=float, sep=' ')  # Adjust dtype and sep as needed\n",
        "                vectors.append(vector)\n",
        "\n",
        "# Convert vectors list to a single numpy array\n",
        "vectors = np.stack(vectors)\n",
        "\n",
        "# Now you can use startup_data and vectors as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLnFIfmG3JRI",
        "outputId": "28402f1f-279f-4a4d-f52c-97680d110dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a2e2e2f255d7>:24: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
            "  vector = np.fromstring(content, dtype=float, sep=' ')  # Adjust dtype and sep as needed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client.upload_collection(\n",
        "    collection_name='diseases',\n",
        "    vectors=vectors,\n",
        "    ids=None,  # Vector ids will be assigned automatically\n",
        "    batch_size=256  # How many vectors will be uploaded in a single request?\n",
        ")"
      ],
      "metadata": {
        "id": "S6wxrlT30KOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install qdrant-client[fastembed]"
      ],
      "metadata": {
        "id": "wEi8a-gjFAr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client.recreate_collection(\n",
        "    collection_name='my_collection',\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GflKP0tLFhrY",
        "outputId": "29b1a110-f50c-4f68-9903-f7e3e5291efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from fastembed.embedding import DefaultEmbedding\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "embedding_model = DefaultEmbedding()\n",
        "\n",
        "folder_path = r'/content/dataFolder'\n",
        "for file_name in os.listdir(folder_path):\n",
        "  loader = TextLoader(file_name)\n",
        "  documents = loader.load()\n",
        "  text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)  #might change chunk_overlap\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "\n",
        "\n",
        "loader = TextLoader(\"potato context.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "embeddings: List[np.ndarray] = list(embedding_model.embed(docs))"
      ],
      "metadata": {
        "id": "o2aDh7fwGIJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}